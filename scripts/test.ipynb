{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hemiSwap_consts as hconsts\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import numpy.matlib as npm\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import spynal as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from spynal.spikes import times_to_bool, rate\n",
    "from itertools import product\n",
    "from sklearn.cross_decomposition import CCA\n",
    "import random\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from scipy.stats import pearsonr\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import KFold\n",
    "from spynal.matIO import loadmat\n",
    "from spynal.spikes import psth\n",
    "\n",
    "def load_and_process_session(session_id, hemiswap):\n",
    "    \"\"\"Load and process a single session data.\"\"\"\n",
    "    filepath = os.path.join(hemiswap.loadDir, f'{session_id}.mat')\n",
    "    print(filepath)\n",
    "    # Load mat file variables\n",
    "    variables = ['ain', 'ainSchema', 'analogChnlInfo', 'electrodeInfo', 'eventSchema', \n",
    "                'fileInfo', 'lfp', 'lfpSchema', 'sessionInfo', 'spikeChnlInfo', \n",
    "                'spikeTimes', 'spikeTimesSchema', 'trialInfo', 'unitInfo']\n",
    "    \n",
    "    data = loadmat(filepath, variables=variables, \n",
    "                  typemap={'trialInfo':'DataFrame'}, verbose=True)\n",
    "    \n",
    "    # Unpack required data\n",
    "    trialInfo = data['trialInfo']\n",
    "    unitInfo = data['unitInfo']\n",
    "    spikeTimes = data['spikeTimes']\n",
    "    \n",
    "    # Get trial indices\n",
    "    trial_indices = {\n",
    "        'noswap_right': np.where((trialInfo['sampleHemifield']=='right') & \n",
    "                                (trialInfo['isSwap']== False))[0],\n",
    "        'noswap_left': np.where((trialInfo['sampleHemifield']=='left') & \n",
    "                               (trialInfo['isSwap']== False))[0],\n",
    "        'swap_right': np.where((trialInfo['sampleHemifield']=='right') & \n",
    "                              (trialInfo['isSwap']== True))[0],\n",
    "        'swap_left': np.where((trialInfo['sampleHemifield']=='left') & \n",
    "                             (trialInfo['isSwap']== True))[0]\n",
    "    }\n",
    "    \n",
    "    # Get hemisphere indices\n",
    "    hemisphere_indices = {\n",
    "        'right': np.where(unitInfo['hemisphere']=='right')[0],\n",
    "        'left': np.where(unitInfo['hemisphere']=='left')[0]\n",
    "    }\n",
    "    \n",
    "    # Process spike data\n",
    "    spike_data = process_spike_data(spikeTimes, trial_indices, hemisphere_indices)\n",
    "    \n",
    "    # Combine all session data\n",
    "    session_data = {**data, **{\n",
    "        'trial_indices': trial_indices,\n",
    "        'hemisphere_indices': hemisphere_indices,\n",
    "        'spike_data': spike_data\n",
    "    }}\n",
    "    \n",
    "    return session_data\n",
    "\n",
    "def process_spike_data(spikeTimes, trial_indices, hemisphere_indices):\n",
    "    \"\"\"Process spike data for different conditions and hemispheres.\"\"\"\n",
    "    spike_data = {}\n",
    "    \n",
    "    # Process no-swap trials\n",
    "    for start_hemi in ['right', 'left']:\n",
    "        trials = trial_indices[f'noswap_{start_hemi}']\n",
    "        spikes = np.squeeze(spikeTimes[trials, :])\n",
    "        \n",
    "        for record_hemi in ['right', 'left']:\n",
    "            hemi_idx = hemisphere_indices[record_hemi]\n",
    "            key = f'{start_hemi}_{record_hemi}_hemi_trials'\n",
    "            spike_data[key] = np.squeeze(spikes[:, hemi_idx])\n",
    "    \n",
    "    return spike_data\n",
    "\n",
    "# Main execution\n",
    "def load_all_sessions(hemiswap, subject=None,n_sessions=None): #n_sessions is the step of sessions to load\n",
    "    \"\"\"Load all sessions for a given subject (or all subjects if None).\"\"\"\n",
    "    sessions = {}\n",
    "    \n",
    "    # Filter sessions by subject if specified\n",
    "    if subject:\n",
    "        session_list = [s for s in hemiswap.sessions['full'] \n",
    "                       if subject in s]\n",
    "        print(session_list)\n",
    "    else:\n",
    "        session_list = hemiswap.sessions['full']\n",
    "    \n",
    "    if n_sessions:\n",
    "        session_list = session_list[::n_sessions]\n",
    "    \n",
    "    # Load each session\n",
    "    for session_id in session_list:\n",
    "        print(f\"Processing session: {session_id}\")\n",
    "        try:\n",
    "            sessions[session_id] = load_and_process_session(session_id, hemiswap)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing session {session_id}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    return sessions\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgsak/miniconda3/envs/hemiswap/lib/python3.8/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hemiSwap_Edith_20180515', 'hemiSwap_Edith_20180517', 'hemiSwap_Edith_20180524', 'hemiSwap_Edith_20180525', 'hemiSwap_Edith_20180529', 'hemiSwap_Edith_20180530', 'hemiSwap_Edith_20180531', 'hemiSwap_Edith_20180601', 'hemiSwap_Edith_20180604', 'hemiSwap_Edith_20180605', 'hemiSwap_Edith_20180606', 'hemiSwap_Edith_20180607', 'hemiSwap_Edith_20180608', 'hemiSwap_Edith_20180612', 'hemiSwap_Edith_20180613', 'hemiSwap_Edith_20180614', 'hemiSwap_Edith_20180615', 'hemiSwap_Edith_20180619', 'hemiSwap_Edith_20180620', 'hemiSwap_Edith_20180621', 'hemiSwap_Edith_20180622']\n",
      "Processing session: hemiSwap_Edith_20180515\n",
      "/mnt/common/datasets/hemiSwap/mat/hemiSwap_Edith_20180515.mat\n"
     ]
    }
   ],
   "source": [
    "hemiswap = hconsts.HemiSwap_consts('miller-lab-3', 'tiergan')\n",
    "sessions = load_all_sessions(hemiswap,'Edith',n_sessions=20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hemiswap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
